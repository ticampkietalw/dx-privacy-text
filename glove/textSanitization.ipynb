{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanitize a text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanitization of a small paragraph using glove.6B.100d.pkl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "from os.path import join\n",
    "import re\n",
    "import numpy as np\n",
    "from cupyx.scipy.spatial import distance\n",
    "import cupy as cp\n",
    "from pathlib import Path\n",
    "import sys\n",
    "# Add the main directory to sys.path to be able to import config\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "from config import ROOT_DIR\n",
    "from utils.dx import sample_noise_vectors\n",
    "\n",
    "# PARAMS\n",
    "distance_metric = \"euclidean\"\n",
    "glove_data_folderpath = ROOT_DIR\n",
    "# END PARAMS\n",
    "glove_dimension_to_filename = {\n",
    "    50: \"glove.6B.50d.pkl\", # 400000 words\n",
    "    100:\"glove.6B.100d.pkl\", # 400000 words\n",
    "    200: \"glove.6B.200d.pkl\", # 400000 words\n",
    "    300:\"glove.6B.300d.pkl\" # 400000 words\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 100\n",
    "with open(join(glove_data_folderpath, glove_dimension_to_filename[hidden_size]), \"rb\") as f:\n",
    "    glove = pickle.load(f)\n",
    "\n",
    "vocab_embs = np.array(list(glove.values()))\n",
    "words_to_id = {word:index for index,word in enumerate(glove.keys())}\n",
    "id_to_words = list(glove.keys())\n",
    "del glove # Save RAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Maria Gonzalez, a patient at Riverside Clinic, was diagnosed with depression on March 5, 2023. She currently lives at 789 Oak Drive, San Francisco. Maria has been prescribed medication and is undergoing weekly therapy sessions.\"\n",
    "\n",
    "# Splitting the paragraph based on spaces, commas, and dots\n",
    "split_text = re.split(r'(\\s+|,|\\.)', text)\n",
    "\n",
    "# Removing any empty strings from the result (due to multiple delimiters)\n",
    "split_text = [word for word in split_text if word.strip()]\n",
    "\n",
    "sanitization_excluded = [\",\", \".\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanitize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 10\n",
    "\n",
    "sanitized_text_split = []\n",
    "for word in split_text:\n",
    "    if word in sanitization_excluded:\n",
    "        sanitized_text_split.append(word)\n",
    "        continue\n",
    "    try:\n",
    "        word_id = words_to_id[word.lower()]\n",
    "    except KeyError:\n",
    "        print(f\"{word.lower()} is not in the vocabulary.\")\n",
    "        break\n",
    "    \n",
    "    word_emb = vocab_embs[word_id]\n",
    "    noise = sample_noise_vectors(dimension=hidden_size,\n",
    "                                    shape1=1,\n",
    "                                    shape2=1,\n",
    "                                    epsilon=epsilon)[0][0]\n",
    "    # Adding noise to embeddings\n",
    "    noisy_embedding = word_emb + noise\n",
    "\n",
    "    # Convert embedding back to text via Nearest neighbor\n",
    "    noisy_word_id = distance.cdist([noisy_embedding], vocab_embs, distance_metric)[0].argmin().get()\n",
    "    noisy_word = id_to_words[noisy_word_id]\n",
    "    sanitized_text_split.append(noisy_word)\n",
    "\n",
    "' '.join(sanitized_text_split)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dx-privacy-text",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
