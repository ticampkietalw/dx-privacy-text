{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Close Neighbors $d_\\mathcal{X}$-privacy frequencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "import sys\n",
    "# Add the main directory to sys.path to be able to import config\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "from config import ROOT_DIR\n",
    "from utils.dx import sample_noise_vectors, noisy_embeddings_to_ids\n",
    "from utils.tools import rank_neighbors\n",
    "\n",
    "# PARAMS\n",
    "distance_metric = \"euclidean\"\n",
    "fasttext_data_folderpath = ROOT_DIR\n",
    "# END PARAMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average several words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(join(fasttext_data_folderpath, \"wiki.en.pkl\"), \"rb\") as f:\n",
    "    fasttext = pickle.load(f)\n",
    "\n",
    "vocab_embs = np.array(list(fasttext.values()))\n",
    "vocab_size = vocab_embs.shape[0]\n",
    "hidden_size = vocab_embs.shape[1]\n",
    "del fasttext # Save RAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select *number_of_words* random words and rank their neighbors according to their distance with the word in the embedding space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_words = 5000\n",
    "words_ids = np.random.randint(0, vocab_size, size=number_of_words)\n",
    "words_embs = vocab_embs[words_ids]\n",
    "\n",
    "words_neighbors_ranked = rank_neighbors(words_embs, vocab_embs, distance_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add noise to the embeddings of the words following the $d_x$-privacy mechanism and count which neighbor was chosen, represented by its rank in the neighbor list of the initial word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons = [i for i in range(1, 51)]\n",
    "neighbor_counted_occurences = {}\n",
    "\n",
    "for epsilon in epsilons:\n",
    "    embeddings = np.copy(words_embs)\n",
    "    noise = sample_noise_vectors(dimension=hidden_size,\n",
    "                                        shape1=1,\n",
    "                                        shape2=number_of_words,\n",
    "                                        epsilon=epsilon)[0]\n",
    "    # Adding noise to embeddings\n",
    "    noisy_embedding = embeddings + noise\n",
    "\n",
    "    # Convert embedding back to text via Nearest neighbor Search\n",
    "    noisy_word_ids = noisy_embeddings_to_ids(noisy_embedding, vocab_embs, distance_metric)\n",
    "\n",
    "    # for all words_ids, get the rank k of noisy_word_ids[i] and increase a counter at index k\n",
    "    noisy_word_ids_ranks = words_neighbors_ranked[np.arange(number_of_words), noisy_word_ids] # This line, for all the elements i in the first dimension of words_neighbors_ranked, gets the particular value pointed by the index which is stored at noisy_word_ids[i]\n",
    "    noisy_word_ids_ranks_counted = Counter(noisy_word_ids_ranks)\n",
    "    neighbor_counted_occurences[epsilon] = [noisy_word_ids_ranks_counted[k] for k in range(vocab_size)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results are stored in *neighbor_counted_occurences*, which is a dictionary where the keys are integers representing the value of epsilon. The dictionary associates each epsilon with a list, where list[i] contains the number of times the i-th neighbor was chosen as the replacement of a word. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dx-privacy-text",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
