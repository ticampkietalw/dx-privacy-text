{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance to neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "from cupyx.scipy.spatial import distance\n",
    "import cupy as cp\n",
    "from pathlib import Path\n",
    "import sys\n",
    "# Add the main directory to sys.path to be able to import config\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "from config import ROOT_DIR\n",
    "from utils.tools import compute_distances, argsort_chunked\n",
    "\n",
    "# PARAMS\n",
    "distance_metric = \"euclidean\"\n",
    "distances_dtype = np.float16 # Precision of the distances\n",
    "fit_dtype = np.uint32 # Integer size sufficient to encode the number of words in the vocabularies\n",
    "\n",
    "word2vec_data_folderpath = ROOT_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance to two arbitrary neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistics will be averaged for this number of words\n",
    "sample_size = 5000\n",
    "x_rank = 1 # Rank of neighbor x\n",
    "y_rank = 2 # Rank of neighbor y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load word2vec vocabulary and store it into suitable structures\n",
    "with open(join(word2vec_data_folderpath, \"GoogleNews-vectors-negative300.pkl\"), \"rb\") as f:\n",
    "    word2vec = pickle.load(f)\n",
    "\n",
    "vocab_embs = cp.array(list(word2vec.values())) # Put on GPU\n",
    "vocab_size = vocab_embs.shape[0]\n",
    "del word2vec # Save RAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take *sample_size* words and compute the distances against the entire vocabulary and rank their neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_ids = np.random.randint(0, vocab_size, size=sample_size)\n",
    "words_embeddings = vocab_embs[words_ids]\n",
    "\n",
    "distances = compute_distances(words_embeddings, vocab_embs, distance_metric, dtype=distances_dtype)\n",
    "\n",
    "# For each word, get a sorted list of their neighbors.\n",
    "word_neighbors = argsort_chunked(distances, fit_dtype)\n",
    "\n",
    "# For each word, get a sorted list of the distances with the entire vocabulary.\n",
    "# Instead of sorting again, benefit from word_neighbors.\n",
    "# Doing distances[word_neighbors] here would not work as word_neighbors is a 2D array and would\n",
    "# result in numpy advanced indexing\n",
    "sorted_distances = np.take_along_axis(distances, word_neighbors, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each word, compute the distance to their *x*-th and *y*-th neighbor, and between these two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance to the neighbor x\n",
    "distances_to_x = sorted_distances[:, x_rank]\n",
    "\n",
    "# Distance to the neighbor y\n",
    "distances_to_y = sorted_distances[:, y_rank]\n",
    "\n",
    "# Gather the ids of x and y\n",
    "x_neighbors = word_neighbors[:, x_rank:x_rank+1]\n",
    "y_neighbors = word_neighbors[:, y_rank:y_rank+1]\n",
    "x_and_y_neighbors = np.concatenate((x_neighbors, y_neighbors), axis=1)\n",
    "\n",
    "# Compute the distance between x and y\n",
    "distances_between_x_and_y = np.empty((sample_size), dtype=distances_dtype)\n",
    "for i in range(sample_size):\n",
    "    # Using cdist because cupyx.scipy.spatial.distance.euclidean has a bug https://github.com/cupy/cupy/issues/8288\n",
    "    distances_between_x_and_y[i] = distance.cdist(vocab_embs[x_and_y_neighbors[i][0]:x_and_y_neighbors[i][0]+1], vocab_embs[x_and_y_neighbors[i][1]:x_and_y_neighbors[i][1]+1], distance_metric).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Average half distance to neighbor {x_rank} = {distances_to_x.mean()/2}\")\n",
    "print(f\"Average half distance to neighbor {y_rank} = {distances_to_y.mean()/2}\")\n",
    "print(f\"Average eq19 for neighbor {x_rank} and {y_rank} = {(((distances_to_y**2)-(distances_to_x**2))/(2*distances_between_x_and_y)).mean()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dx-privacy-text",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
